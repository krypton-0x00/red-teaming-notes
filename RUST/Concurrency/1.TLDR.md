The calls to `thread::sleep` force a thread to stop its execution for a short duration, allowing a different thread to run.

#ISSUE: New Thread will be stopped when the main thread ends whether or not it has finished running
```rust
use std::thread;  
use std::time::Duration;  
  
fn main(){  
    thread::spawn(||{  
        for i in 1..100{  
            println!("Spawned Thread: {}", i);  
            thread::sleep(Duration::from_millis(1));  
        }  
    });  
    for i in 1..10{  
        println!("Main Thread: {}", i);  
        thread::sleep(Duration::from_millis(1));  
    }  
 ```

```output 
Main Thread: 1
Spawned Thread: 1
Main Thread: 2
Spawned Thread: 2
Main Thread: 3
Spawned Thread: 3
Main Thread: 4
Spawned Thread: 4
Main Thread: 5
Spawned Thread: 5
Spawned Thread: 6
Main Thread: 6
Spawned Thread: 7
Main Thread: 7
Spawned Thread: 8
Main Thread: 8
Spawned Thread: 9
Main Thread: 9
Spawned Thread: 10
```
## Waiting for All Threads to Finish Using join Handles
`.join` makes sure the spawned thread finishes before main exits.

```rust
fn main(){  
    let handle = thread::spawn(||{  
        for i in 1..100{  
            println!("Spawned Thread: {}", i);  
            thread::sleep(Duration::from_millis(1));  
        }  
    });  
    for i in 1..10 {  
        println!("Main Thread: {}", i);  
        thread::sleep(Duration::from_millis(1));  
    }  
    handle.join().unwrap();
}
```
## Calling `.join()` before the main for loop
```rust
fn main(){  
    let handle = thread::spawn(||{  
        for i in 1..100{  
            println!("Spawned Thread: {}", i);  
            thread::sleep(Duration::from_millis(1));  
        }  
    });  
    handle.join().unwrap();  //CALLING join() 
    for i in 1..10 {  
        println!("Main Thread: {}", i);  
        thread::sleep(Duration::from_millis(1));  
    }  
}
```

#Result: The main thread will wait for the spawned thread to finish and then run its for loop, so the output won’t be interleaved anymore.

```output
Spawned Thread: 1
Spawned Thread: 2
Spawned Thread: up to n ....
Main Thread: 1
Main Thread: 2
Main Thread: 3
Main Thread: 4
Main Thread: 5
Main Thread: 6
Main Thread: 7
Main Thread: 8
Main Thread: 9

```
## Using move Closures with Threads
#ISSUE Rust infers how to capture v, and because `println!` only needs a reference to `v`, the closure tries to borrow v. However, there’s a problem: Rust can’t tell how long the spawned thread will run, so it doesn’t know whether the refer- ence to v will always be valid
```rust
fn main(){  
    let v = vec![1,2,3];  
    let handle = thread::spawn(||{  
        println!("{:?}",v);   //ERROR: 
  
    });  
    handle.join().unwrap();  
  
}
```

#FIX: using move

```rust
fn main(){  
    let v = vec![1,2,3];  
    let handle = thread::spawn(move ||{  
        println!("{:?}",v);  
  
    });  
    handle.join().unwrap();  
  
}
```

# Communication BW Threads.
-> There are two ways :
	1. Using Message Passing (MPSC channels)
	2. Using Shared Memory (MUTEXs)
## Using Message Passing to Transfer Data Between Threads
#channels: **channels** are a mechanism for communication between threads, allowing data to be sent from one thread to another. They are part of Rust's concurrency model and are implemented in the `std::sync::mpsc` module, which stands for **multi-producer, single-consumer**.

### **Channel Communication Methods**

1. **`send` (on Sender)**:
    
    - Sends data to the channel.
    - Returns an error if the receiver has been dropped.
2. **`recv` (on Receiver)**:
    
    - Blocks the thread until a message is available.
3. **`try_recv`**:
    
    - Non-blocking call that immediately checks for a message.
    - Returns `Err` if no message is available.
4. **`iter`**:
    
    - Allows iterating over the messages in the receiver.
    - Stops when the channel is closed.
```rust
  
fn main(){  
    let (tx,rx) = mpsc::channel();  
    let handle = thread::spawn(move ||{  
        let x = 12;  
        tx.send(x).unwrap();  
    });  
  
    let received = rx.recv().unwrap();  
    println!("Got: {}",received);  
  
    handle.join().unwrap();  
  
}
```

#Mutliple Values
```rust
fn main(){  
    let (tx,rx) = mpsc::channel();  
  
    let handle = thread::spawn(move ||{  
        let vals = vec![ 
	        String::from("hi"),
	        String::from("from"), 
	        String::from("the"),
	        String::from("thread") 
	    ];  
  
        for val in vals{  
            tx.send(val).unwrap(); 
            thread::sleep(Duration::from_secs(1)); 
        }  
    });  
  
    for received in rx{  
        println!("Got {}",received);  
    }  
  
    handle.join().unwrap();  
}
```

OUTPUT: Delay of 1 sec in between each print
```output
Got hi
Got from
Got the
Got thread

```
### Multiple Producers (Multiple Transmitters)
```rust
use std::thread;  
use std::time::Duration;  
use std::sync::mpsc;  
  
fn main(){  
    let (tx,rx) = mpsc::channel();  //Tx 1
    let tx1 = mpsc::Sender::clone(&tx); // Tx 2 
	//T1
    thread::spawn(move ||{  
        let vals = vec![ String::from("hi"), String::from("from"), String::from("the"), String::from("thread") ];  
  
        for val in vals{  
            tx1.send(val).unwrap();  
            thread::sleep(Duration::from_secs(1));  
        }  
    });  
    //T2
    thread::spawn(move ||{  
        let vals = vec![ String::from("hi"), String::from("from"), String::from("the"), String::from("thread") ];  
  
        for val in vals{  
            tx.send(val).unwrap();  
            thread::sleep(Duration::from_secs(1));  
        }  
    });  
  
    for received in rx{  
        println!("Got {}",received);  
    }  
  
  
  
}
```
#OUTPUT: space bw them represents the delay of 1 sec
```output
Got hi
Got hi

Got from
Got from

Got the
Got the

Got thread
Got thread

```

## Shared Memory
### Using Mutexes to Allow Access to Data from One Thread at a Time
Communication between threads using **shared memory** in Rust involves multiple threads accessing a common data structure. Rust provides tools like **`Mutex`**, **`RwLock`**, and **`Arc`** to make this safe by enforcing strict ownership and borrowing rules at compile time. Let’s break it down:
### **Key Concepts**

1. **`Mutex` (Mutual Exclusion)**:
    
    - Ensures that only one thread can access the shared data at a time.
    -  `Mutex<T>` provides interior mutability, as the Cell family does
    - Other threads trying to access it will block until the lock is available.
    - The lock is a **data structure** that is part of the mutex that keeps track of who currently has exclusive access to the data. 
    - Therefore, the **mutex** is described as guarding the data it holds via the locking system
    
	1. `Mutexes` *have a reputation for being difficult to use because you have to remember two rules:*
		 • _You must attempt to acquire the lock before using the data. 
		 • When you’re done with the data that the mutex guards, you must unlock the data so other threads can acquire the lock_
	2. As you might suspect, `Mutex<T>` is a smart pointer. More accurately, the call to lock returns a smart pointer called MutexGuard 
	3. This smart pointer implements `Deref` to point at our inner data; the smart pointer also has a `Drop` implementation that releases the lock automatically when a `MutexGuard` goes out of scope

#Example : In Single Threaded Context.
```rust
use std::sync::Mutex;  
  
fn main(){  
    let m = Mutex::new(5);  
    {  
        let mut num = m.lock().unwrap();  
        *num = 6;  
    }  
    println!("m = {:?}", m);  
}
```

## Multiple Ownership with Multiple Threads

#Problem : Cannot have multiple owners.
```rust
use std::sync::Mutex;  
use std::thread;  
  
fn main(){  
    let counter = Mutex::new(0);  
    let mut handles = vec![];  
  
  
    let handle = thread::spawn(move ||{//value moved to the thread
        let mut num = counter.lock().unwrap();  
        *num +=1;  
    });  
    handles.push(handle);  
  
    let handle2 = thread::spawn(move ||{ //ERROR: Cannot move the value. 
        let mut num = counter.lock().unwrap();  
        *num +=1;  
    });  
    handles.push(handle2);  
  
  
    for handle in handles {  
        handle.join().unwrap();  
    }  
    println!("{:?}", counter.lock().unwrap());  
  
}
```

#problem2 : `Rc<Mutex<i32>>` cannot be sent between threads safely

```rust
fn main(){  
    let counter = Rc::new(Mutex::new(0));  
    let mut handles = vec![];  
  
    for _ in 0..10 {  
        let counter = Rc::clone(&counter);  
        let handle = thread::spawn(move ||{  
            let mut num = counter.lock().unwrap();  
            *num +=1;  
        });  
        handles.push(handle);  
    }  
  
  
  
    for handle in handles {  
        handle.join().unwrap();  
    }  
    println!("{:?}", *counter.lock().unwrap());  
  
}
```

Unfortunately, `Rc<T>` is not safe to share across threads. When `Rc<T>` manages the reference count, it adds to the count for each call to clone and subtracts from the count when each clone is dropped. 
But it doesn’t use any concurrency primitives to make sure that changes to the count can’t be interrupted by another thread. This could lead to wrong countssubtle bugs that could in turn lead to memory leaks or a value being dropped before we’re done with it. What we need is a type exactly like `Rc<T>` but one that makes changes to the reference count in a thread-safe way

## Atomic Reference Counting with `Arc<T>`
`Arc<T>` in Rust stands for **Atomic Reference Counted** and is a smart pointer that enables **shared ownership** of data across multiple threads. Unlike `Rc<T>`, which is not thread-safe, `Arc<T>` uses atomic operations to update the reference count, making it suitable for concurrent environments.

`Atomic operations` are **hardware-supported** instructions that ensure a computation (like incrementing or decrementing a counter) happens **without interruption** by other threads. This guarantees correctness even in the presence of concurrent access.

### **How `Arc<T>` Works**
1. **Reference Counting**:
    - `Arc<T>` keeps a **reference count** of how many `Arc<T>` instances point to the same data.
    - When an `Arc<T>` is cloned, the count is incremented.
    - When an `Arc<T>` is dropped, the count is decremented.
    - When the count reaches zero, the data is deallocated.
2. **Atomic Operations**:
    - `Arc<T>` uses atomic increments and decrements for the reference count, ensuring safety across threads.


## Multiple Readers or one writer.
`RwLock<T>` is a synchronization primitive in Rust that allows **multiple readers** or **one writer** access to a shared resource. It ensures thread-safe, concurrent access to a value while maintaining performance.

## Extensible Concurrency with the sync and send traits
Rust's **`Sync`** and **`Send`** traits are core building blocks for ensuring safe concurrency. These traits define how types can be shared and transferred between threads, enabling extensible concurrency.
### **`RwLock<T>` in Rust**

`RwLock<T>` is a synchronization primitive in Rust that allows **multiple readers** or **one writer** access to a shared resource. It ensures thread-safe, concurrent access to a value while maintaining performance.

---

### **When to Use `RwLock`?**

Use `RwLock` when:

- **Read-heavy workload**: You have more read operations than write operations.
- You want **concurrent access for readers** but need to ensure **exclusive access for writers**.

---

### **How `RwLock` Works**

- **Read Lock (`read`)**: Allows multiple readers to access the value concurrently.
- **Write Lock (`write`)**: Grants exclusive access to the value, blocking both readers and other writers.

### **API Overview**

- **`read`**:
    - Acquires a shared lock for reading.
    - Returns a guard (`RwLockReadGuard`) that allows immutable access.
- **`write`**:
    - Acquires an exclusive lock for writing.
    - Returns a guard (`RwLockWriteGuard`) that allows mutable access.
- Both `read` and `write` return `Result` to handle lock poisoning.

```rust
use std::sync::{Arc, RwLock};
use std::thread;

fn main() {
    let data = Arc::new(RwLock::new(0)); // Shared resource.

    let mut handles = vec![];

    // Spawn multiple reader threads
    for _ in 0..3 {
        let data_clone = Arc::clone(&data);
        let handle = thread::spawn(move || {
            let read_lock = data_clone.read().unwrap(); // Acquire read lock
            println!("Read: {}", *read_lock);
        });
        handles.push(handle);
    }

    // Spawn a writer thread
    {
        let data_clone = Arc::clone(&data);
        let handle = thread::spawn(move || {
            let mut write_lock = data_clone.write().unwrap(); // Acquire write lock
            *write_lock += 1;
            println!("Write: {}", *write_lock);
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    // Final value
    println!("Final Value: {:?}", *data.read().unwrap());
}

```

```output
Read: 0
Read: 0
Read: 0
Write: 1
Final Value: 1

```

## **The `Send` Trait**

The `Send` trait allows ownership of a value to be **transferred safely between threads**.
```rust
use std::thread;

let data = 42; // `i32` is `Send` by default.

thread::spawn(move || {
    println!("Data: {}", data); // Ownership is moved to the new thread.
}).join().unwrap();

```

## **The `Sync` Trait**

The `Sync` trait allows a value to be **shared safely between threads** via references.

```rust
use std::sync::Arc;
use std::thread;

let data = Arc::new(42); // `Arc<T>` is `Sync` if `T` is `Sync`.

let data_clone = Arc::clone(&data);
thread::spawn(move || {
    println!("Shared Data: {}", *data_clone); // Safe sharing between threads.
}).join().unwrap();

```

## **Relationship Between `Sync` and `Send`**

- If a type is `Sync`, `&T` can be safely shared between threads.
- If a type is `Send`, `T` can be safely moved between threads.